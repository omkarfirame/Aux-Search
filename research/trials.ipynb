{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from AuxSearch.components.PDFTextExtractor import PDFConverter\n",
    "from AuxSearch.components.TextChunkerEmbedder import TextProcessor\n",
    "from AuxSearch.components.Model import ChainLoader\n",
    "# from AuxSearch.components.StreamlitUserInput import UserInputHandler\n",
    "\n",
    "pdfconverter = PDFConverter()\n",
    "textprocessor = TextProcessor()\n",
    "chains = ChainLoader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from AuxSearch.components.PDFTextExtractor import PDFConverter\n",
    "from AuxSearch.components.TextChunkerEmbedder import TextProcessor\n",
    "from AuxSearch.components.Model import ChainLoader\n",
    "from langchain.embeddings import OllamaEmbeddings \n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from AuxSearch.constants import *\n",
    "\n",
    "pdfconverter = PDFConverter()\n",
    "textprocessor = TextProcessor()\n",
    "chains = ChainLoader()\n",
    "\n",
    "\n",
    "def user_input(user_question):\n",
    "    embeddings = OllamaEmbeddings()\n",
    "    \n",
    "    new_db = FAISS.load_local(\"faiss_index\", embeddings)\n",
    "    docs = new_db.similarity_search(user_question)\n",
    "\n",
    "    chain = chains.get_chains()\n",
    "\n",
    "    \n",
    "    response = chain(\n",
    "        {\"input_documents\":docs, \"question\": user_question}\n",
    "        , return_only_outputs=True)\n",
    "\n",
    "    print(response)\n",
    "    st.write(\"Reply: \", response[\"output_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings()\n",
    "\n",
    "vectorstore = FAISS.load_local(\"faiss_index\",embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type = \"similarity\",k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"What is the name on resume?\"\n",
    "pdf_files = \"Omkar_Firame_Resume.pdf\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = pdfconverter.pdf_to_text(pdf_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_chunks = textprocessor.get_chunks(raw_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Omkar\\nFirame\\n+919404350615\\n|\\nE-Mail\\n|\\nLinkedin\\n|\\nGitHub\\nSUMMAR Y:\\nData\\nScientist\\nwith\\nstrong\\nMachine\\nLearning\\nfoundation\\nand\\n3+\\nyears\\nof\\nexperience\\nin\\ndeveloping\\nrobust\\nML\\nmodels\\nusing\\npredictive\\ndata\\nmodeling,\\nanalyze\\ndata\\nto\\ndeliver\\ninsights\\nand\\nimplement\\naction-oriented\\nsolutions\\nto\\ncomplex\\nbusiness\\nproblems.\\nTECHNICAL\\nSKILLS:\\nPython,\\nR,\\nMachine\\nLearning,\\nDeep\\nLearning,\\nPyTorch,\\nIguazio,\\nKubeFlow\\nPipeline,\\nAzure\\nDatabricks,\\nDask,\\nWeb\\nScraping\\n(Selenium),\\nGit,\\nEXPERIENCE:\\nData\\nScientist\\n-\\nWynum\\nAutomation\\nServices\\nPvt.\\nLtd\\n|\\nApril\\n2023\\n-\\nPresent\\n●\\nManaged\\na\\nproject\\nimplementing\\nan\\ninformation\\nretrieval\\nsystem\\nfor\\nextracting\\nrelevant\\npress\\nreleases\\nfrom\\nonline\\nsources.\\n●\\nApplied\\nadvanced\\ndata\\npreprocessing\\ntechniques\\nto\\ncleanse\\nand\\nstructure\\ncontent,\\nenhancing\\ncategorization\\nand\\nanalytical\\ncapabilities.\\n●\\nDeveloped\\ncustom\\nweb\\nscrapers\\nusing\\nPython\\n(Beautiful\\nSoup,\\nRequests)\\nfor\\nprecise\\nand\\ntargeted\\ncontent\\nextraction.\\nInitiated\\nan\\nindependent\\nproject\\nto\\nautomate\\nDOCX\\nfile\\ngeneration\\nfrom\\ntext\\ndata,\\nshowcasing\\nproactive\\nand\\ninnovative\\nproblem-solving.\\nData\\nScientist\\n-\\nTata\\nConsultancy\\nServices\\n|\\nFeb\\n2021\\n-\\nMarch\\n2023\\n●\\nSpearheaded\\nend-to-end\\ndata\\ninitiatives\\ninvolving\\ndata\\nextraction,\\ntransformation,\\nand\\nloading\\nfrom\\nAzure\\nData\\nLake\\nfor\\nstreamlined\\nprocesses\\nin\\nData\\nPreparation,\\nCleaning,\\nand\\nModel\\nBuilding.\\n●\\nEngineered\\nand\\nimplemented\\nrobust\\npipelines,\\nutilizing\\nKubeFlow ,\\na\\ncustom\\nManual\\npipeline,\\nand\\nthe\\nmlrun\\nMLOps\\norchestration\\nframework\\non\\nthe\\nIguazio\\nplatform,\\nensuring\\nseamless\\nautomation\\non\\na\\nscheduled\\nbasis.\\n●\\nOrchestrated\\ndata\\ntransformations\\nto\\nmeet\\nAPI\\nrequirements,\\nsystematically\\nschematizing\\ndatasets\\nfor\\nenhanced\\ncompatibility\\nand\\nintegration.\\nApplied\\nDask\\ndistributed\\ncomputing\\nfor\\nefficient\\nhandling\\nof\\nlarge-scale\\ndatasets,\\noptimizing\\ndata\\nprocessing\\nand\\nanalysis\\nworkflows.\\nIntern\\n-\\nThoughtworks\\nTechnologies\\nIndia\\nPvt.\\nLtd\\n|\\nJan\\n2020\\n-\\nSept\\n-\\n2020\\n●\\nPioneered\\nthe\\napplication\\nof\\nmachine\\nlearning\\nin\\nthe\\nmedical\\ndomain,\\nfocusing\\non\\npredicting\\ndrug\\nproperties\\nbased\\non\\nchemical\\ncomposition.\\n●\\nAutomated\\nraw\\ndata\\nprocessing\\nwith\\nPython\\nscripts\\nand\\nkey\\nlibraries\\n(chemoPy ,\\nPyBioMed,\\nModred),\\nstreamlining\\ndata\\npreparation\\nfor\\npredictive\\nmodeling.\\n●\\nDemonstrated\\nexpertise\\nin\\ndrug\\ntoxicity\\nprediction,\\nsecuring\\n6th\\nposition\\nin\\nthe\\nTox21\\nchallenge\\n(2014-15)\\nwith\\nan\\noutstanding\\naverage\\nAUC\\nscore\\nof\\n0.8347.\\nPROJECTS:\\nText\\nSummarization\\n-\\n[\\nLink\\n]\\n●\\nDeveloped\\na\\nText\\nSummarization\\npersonal\\nproject,\\nleveraging\\nStreamlit\\nfor\\nan\\nintuitive\\nuser\\ninterface\\nthat\\nenhances\\nuser\\nexperience\\nand\\ninteraction.\\n●\\nImplemented\\na\\nmodularized\\nstructure,\\nintegrating\\nthe\\nT5\\nsmall\\nmodel\\nfor\\nefficient\\nand\\neffective\\ntext\\nsummarization,\\nshowcasing\\na\\nsystematic\\nand\\norganized\\napproach\\nto\\nproject\\ndevelopment.\\nEDUCA TION\\n-\\nM.TECH\\n-\\nMathematical\\nModeling\\nAnd\\nSimulation\\n-\\nCentre\\nfor\\nModelling\\nand\\nSimulation,\\nSPPU,\\nPune\\n|\\n2020\\nB.E\\n-\\nMechanical\\nEngineering\\n-\\nBharti\\nVidyapeeth's\\nCollege\\nof\\nEngineering,\\nKolhapur\\n|\\n|\\n2016\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "textprocessor.get_vector_store(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_db = FAISS.load_local(\"faiss_index\", embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x1df303c1df0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "docs = new_db.similarity_search(user_question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Omkar\\nFirame\\n+919404350615\\n|\\nE-Mail\\n|\\nLinkedin\\n|\\nGitHub\\nSUMMAR Y:\\nData\\nScientist\\nwith\\nstrong\\nMachine\\nLearning\\nfoundation\\nand\\n3+\\nyears\\nof\\nexperience\\nin\\ndeveloping\\nrobust\\nML\\nmodels\\nusing\\npredictive\\ndata\\nmodeling,\\nanalyze\\ndata\\nto\\ndeliver\\ninsights\\nand\\nimplement\\naction-oriented\\nsolutions\\nto\\ncomplex\\nbusiness\\nproblems.\\nTECHNICAL\\nSKILLS:\\nPython,\\nR,\\nMachine\\nLearning,\\nDeep\\nLearning,\\nPyTorch,\\nIguazio,\\nKubeFlow\\nPipeline,\\nAzure\\nDatabricks,\\nDask,\\nWeb\\nScraping\\n(Selenium),\\nGit,\\nEXPERIENCE:\\nData\\nScientist\\n-\\nWynum\\nAutomation\\nServices\\nPvt.\\nLtd\\n|\\nApril\\n2023\\n-\\nPresent\\n●\\nManaged\\na\\nproject\\nimplementing\\nan\\ninformation\\nretrieval\\nsystem\\nfor\\nextracting\\nrelevant\\npress\\nreleases\\nfrom\\nonline\\nsources.\\n●\\nApplied\\nadvanced\\ndata\\npreprocessing\\ntechniques\\nto\\ncleanse\\nand\\nstructure\\ncontent,\\nenhancing\\ncategorization\\nand\\nanalytical\\ncapabilities.\\n●\\nDeveloped\\ncustom\\nweb\\nscrapers\\nusing\\nPython\\n(Beautiful\\nSoup,\\nRequests)\\nfor\\nprecise\\nand\\ntargeted\\ncontent\\nextraction.\\nInitiated\\nan\\nindependent\\nproject\\nto\\nautomate\\nDOCX\\nfile\\ngeneration\\nfrom\\ntext\\ndata,\\nshowcasing\\nproactive\\nand\\ninnovative\\nproblem-solving.\\nData\\nScientist\\n-\\nTata\\nConsultancy\\nServices\\n|\\nFeb\\n2021\\n-\\nMarch\\n2023\\n●\\nSpearheaded\\nend-to-end\\ndata\\ninitiatives\\ninvolving\\ndata\\nextraction,\\ntransformation,\\nand\\nloading\\nfrom\\nAzure\\nData\\nLake\\nfor\\nstreamlined\\nprocesses\\nin\\nData\\nPreparation,\\nCleaning,\\nand\\nModel\\nBuilding.\\n●\\nEngineered\\nand\\nimplemented\\nrobust\\npipelines,\\nutilizing\\nKubeFlow ,\\na\\ncustom\\nManual\\npipeline,\\nand\\nthe\\nmlrun\\nMLOps\\norchestration\\nframework\\non\\nthe\\nIguazio\\nplatform,\\nensuring\\nseamless\\nautomation\\non\\na\\nscheduled\\nbasis.\\n●\\nOrchestrated\\ndata\\ntransformations\\nto\\nmeet\\nAPI\\nrequirements,\\nsystematically\\nschematizing\\ndatasets\\nfor\\nenhanced\\ncompatibility\\nand\\nintegration.\\nApplied\\nDask\\ndistributed\\ncomputing\\nfor\\nefficient\\nhandling\\nof\\nlarge-scale\\ndatasets,\\noptimizing\\ndata\\nprocessing\\nand\\nanalysis\\nworkflows.\\nIntern\\n-\\nThoughtworks\\nTechnologies\\nIndia\\nPvt.\\nLtd\\n|\\nJan\\n2020\\n-\\nSept\\n-\\n2020\\n●\\nPioneered\\nthe\\napplication\\nof\\nmachine\\nlearning\\nin\\nthe\\nmedical\\ndomain,\\nfocusing\\non\\npredicting\\ndrug\\nproperties\\nbased\\non\\nchemical\\ncomposition.\\n●\\nAutomated\\nraw\\ndata\\nprocessing\\nwith\\nPython\\nscripts\\nand\\nkey\\nlibraries\\n(chemoPy ,\\nPyBioMed,\\nModred),\\nstreamlining\\ndata\\npreparation\\nfor\\npredictive\\nmodeling.\\n●\\nDemonstrated\\nexpertise\\nin\\ndrug\\ntoxicity\\nprediction,\\nsecuring\\n6th\\nposition\\nin\\nthe\\nTox21\\nchallenge\\n(2014-15)\\nwith\\nan\\noutstanding\\naverage\\nAUC\\nscore\\nof\\n0.8347.\\nPROJECTS:\\nText\\nSummarization\\n-\\n[\\nLink\\n]\\n●\\nDeveloped\\na\\nText\\nSummarization\\npersonal\\nproject,\\nleveraging\\nStreamlit\\nfor\\nan\\nintuitive\\nuser\\ninterface\\nthat\\nenhances\\nuser\\nexperience\\nand\\ninteraction.\\n●\\nImplemented\\na\\nmodularized\\nstructure,\\nintegrating\\nthe\\nT5\\nsmall\\nmodel\\nfor\\nefficient\\nand\\neffective\\ntext\\nsummarization,\\nshowcasing\\na\\nsystematic\\nand\\norganized\\napproach\\nto\\nproject\\ndevelopment.\\nEDUCA TION\\n-\\nM.TECH\\n-\\nMathematical\\nModeling\\nAnd\\nSimulation\\n-\\nCentre\\nfor\\nModelling\\nand\\nSimulation,\\nSPPU,\\nPune\\n|\\n2020\\nB.E\\n-\\nMechanical\\nEngineering\\n-\\nBharti\\nVidyapeeth's\\nCollege\\nof\\nEngineering,\\nKolhapur\\n|\\n|\\n2016\")]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_template = \"\"\"\n",
    "#     Answer the question as detailed as possible from the provided context, make sure to provide all the details, if the answer is not in\n",
    "#     provided context just say, \"answer is not available in the context\", don't provide the wrong answer\\n\\n\n",
    "#     Context:\\n {context}?\\n\n",
    "#     Question: \\n{question}\\n\n",
    "\n",
    "#     Answer:\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "    Answer the question to the point without description. If answer not found in context reply \"Answer Not found\"\\n\\n\n",
    "    Context:\\n {context}?\\n\n",
    "    Question: \\n{question}\\n\n",
    "\n",
    "    Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import CTransformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/omkar/Downloads/LLama2-Model/llama-2-7b-chat.ggmlv3.q8_0.bin')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Omkar\\Anaconda3\\envs\\pyenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "model = CTransformers(model = 'C:/Users/omkar/Downloads/LLama2-Model/llama-2-7b-chat.ggmlv3.q8_0.bin',model_type='llama')\n",
    "prompt = PromptTemplate(template=prompt_template,input_variables=[\"context\",\"question\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], template='\\n    Answer the question as detailed as possible from the provided context, make sure to provide all the details, if the answer is not in\\n    provided context just say, \"answer is not available in the context\", don\\'t provide the wrong answer\\n\\n\\n    Context:\\n {context}?\\n\\n    Question: \\n{question}\\n\\n\\n    Answer:\\n')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\n",
    "        \"context\":retriever,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of tokens (1603) exceeded maximum context length (512).\n"
     ]
    }
   ],
   "source": [
    "rag_chain.invoke(user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "chain = load_qa_chain(model,chain_type=\"stuff\",prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Omkar\\nFirame\\n+919404350615\\n|\\nE-Mail\\n|\\nLinkedin\\n|\\nGitHub\\nSUMMAR Y:\\nData\\nScientist\\nwith\\nstrong\\nMachine\\nLearning\\nfoundation\\nand\\n3+\\nyears\\nof\\nexperience\\nin\\ndeveloping\\nrobust\\nML\\nmodels\\nusing\\npredictive\\ndata\\nmodeling,\\nanalyze\\ndata\\nto\\ndeliver\\ninsights\\nand\\nimplement\\naction-oriented\\nsolutions\\nto\\ncomplex\\nbusiness\\nproblems.\\nTECHNICAL\\nSKILLS:\\nPython,\\nR,\\nMachine\\nLearning,\\nDeep\\nLearning,\\nPyTorch,\\nIguazio,\\nKubeFlow\\nPipeline,\\nAzure\\nDatabricks,\\nDask,\\nWeb\\nScraping\\n(Selenium),\\nGit,\\nEXPERIENCE:\\nData\\nScientist\\n-\\nWynum\\nAutomation\\nServices\\nPvt.\\nLtd\\n|\\nApril\\n2023\\n-\\nPresent\\n●\\nManaged\\na\\nproject\\nimplementing\\nan\\ninformation\\nretrieval\\nsystem\\nfor\\nextracting\\nrelevant\\npress\\nreleases\\nfrom\\nonline\\nsources.\\n●\\nApplied\\nadvanced\\ndata\\npreprocessing\\ntechniques\\nto\\ncleanse\\nand\\nstructure\\ncontent,\\nenhancing\\ncategorization\\nand\\nanalytical\\ncapabilities.\\n●\\nDeveloped\\ncustom\\nweb\\nscrapers\\nusing\\nPython\\n(Beautiful\\nSoup,\\nRequests)\\nfor\\nprecise\\nand\\ntargeted\\ncontent\\nextraction.\\nInitiated\\nan\\nindependent\\nproject\\nto\\nautomate\\nDOCX\\nfile\\ngeneration\\nfrom\\ntext\\ndata,\\nshowcasing\\nproactive\\nand\\ninnovative\\nproblem-solving.\\nData\\nScientist\\n-\\nTata\\nConsultancy\\nServices\\n|\\nFeb\\n2021\\n-\\nMarch\\n2023\\n●\\nSpearheaded\\nend-to-end\\ndata\\ninitiatives\\ninvolving\\ndata\\nextraction,\\ntransformation,\\nand\\nloading\\nfrom\\nAzure\\nData\\nLake\\nfor\\nstreamlined\\nprocesses\\nin\\nData\\nPreparation,\\nCleaning,\\nand\\nModel\\nBuilding.\\n●\\nEngineered\\nand\\nimplemented\\nrobust\\npipelines,\\nutilizing\\nKubeFlow ,\\na\\ncustom\\nManual\\npipeline,\\nand\\nthe\\nmlrun\\nMLOps\\norchestration\\nframework\\non\\nthe\\nIguazio\\nplatform,\\nensuring\\nseamless\\nautomation\\non\\na\\nscheduled\\nbasis.\\n●\\nOrchestrated\\ndata\\ntransformations\\nto\\nmeet\\nAPI\\nrequirements,\\nsystematically\\nschematizing\\ndatasets\\nfor\\nenhanced\\ncompatibility\\nand\\nintegration.\\nApplied\\nDask\\ndistributed\\ncomputing\\nfor\\nefficient\\nhandling\\nof\\nlarge-scale\\ndatasets,\\noptimizing\\ndata\\nprocessing\\nand\\nanalysis\\nworkflows.\\nIntern\\n-\\nThoughtworks\\nTechnologies\\nIndia\\nPvt.\\nLtd\\n|\\nJan\\n2020\\n-\\nSept\\n-\\n2020\\n●\\nPioneered\\nthe\\napplication\\nof\\nmachine\\nlearning\\nin\\nthe\\nmedical\\ndomain,\\nfocusing\\non\\npredicting\\ndrug\\nproperties\\nbased\\non\\nchemical\\ncomposition.\\n●\\nAutomated\\nraw\\ndata\\nprocessing\\nwith\\nPython\\nscripts\\nand\\nkey\\nlibraries\\n(chemoPy ,\\nPyBioMed,\\nModred),\\nstreamlining\\ndata\\npreparation\\nfor\\npredictive\\nmodeling.\\n●\\nDemonstrated\\nexpertise\\nin\\ndrug\\ntoxicity\\nprediction,\\nsecuring\\n6th\\nposition\\nin\\nthe\\nTox21\\nchallenge\\n(2014-15)\\nwith\\nan\\noutstanding\\naverage\\nAUC\\nscore\\nof\\n0.8347.\\nPROJECTS:\\nText\\nSummarization\\n-\\n[\\nLink\\n]\\n●\\nDeveloped\\na\\nText\\nSummarization\\npersonal\\nproject,\\nleveraging\\nStreamlit\\nfor\\nan\\nintuitive\\nuser\\ninterface\\nthat\\nenhances\\nuser\\nexperience\\nand\\ninteraction.\\n●\\nImplemented\\na\\nmodularized\\nstructure,\\nintegrating\\nthe\\nT5\\nsmall\\nmodel\\nfor\\nefficient\\nand\\neffective\\ntext\\nsummarization,\\nshowcasing\\na\\nsystematic\\nand\\norganized\\napproach\\nto\\nproject\\ndevelopment.\\nEDUCA TION\\n-\\nM.TECH\\n-\\nMathematical\\nModeling\\nAnd\\nSimulation\\n-\\nCentre\\nfor\\nModelling\\nand\\nSimulation,\\nSPPU,\\nPune\\n|\\n2020\\nB.E\\n-\\nMechanical\\nEngineering\\n-\\nBharti\\nVidyapeeth's\\nCollege\\nof\\nEngineering,\\nKolhapur\\n|\\n|\\n2016\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the name on resume?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Omkar\\Anaconda3\\envs\\pyenv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "Number of tokens (1301) exceeded maximum context length (512).\n",
      "Number of tokens (1302) exceeded maximum context length (512).\n",
      "Number of tokens (1303) exceeded maximum context length (512).\n",
      "Number of tokens (1304) exceeded maximum context length (512).\n",
      "Number of tokens (1305) exceeded maximum context length (512).\n",
      "Number of tokens (1306) exceeded maximum context length (512).\n",
      "Number of tokens (1307) exceeded maximum context length (512).\n",
      "Number of tokens (1308) exceeded maximum context length (512).\n",
      "Number of tokens (1309) exceeded maximum context length (512).\n",
      "Number of tokens (1310) exceeded maximum context length (512).\n",
      "Number of tokens (1311) exceeded maximum context length (512).\n",
      "Number of tokens (1312) exceeded maximum context length (512).\n",
      "Number of tokens (1313) exceeded maximum context length (512).\n",
      "Number of tokens (1314) exceeded maximum context length (512).\n",
      "Number of tokens (1315) exceeded maximum context length (512).\n",
      "Number of tokens (1316) exceeded maximum context length (512).\n",
      "Number of tokens (1317) exceeded maximum context length (512).\n",
      "Number of tokens (1318) exceeded maximum context length (512).\n",
      "Number of tokens (1319) exceeded maximum context length (512).\n",
      "Number of tokens (1320) exceeded maximum context length (512).\n",
      "Number of tokens (1321) exceeded maximum context length (512).\n",
      "Number of tokens (1322) exceeded maximum context length (512).\n",
      "Number of tokens (1323) exceeded maximum context length (512).\n",
      "Number of tokens (1324) exceeded maximum context length (512).\n",
      "Number of tokens (1325) exceeded maximum context length (512).\n",
      "Number of tokens (1326) exceeded maximum context length (512).\n",
      "Number of tokens (1327) exceeded maximum context length (512).\n",
      "Number of tokens (1328) exceeded maximum context length (512).\n",
      "Number of tokens (1329) exceeded maximum context length (512).\n",
      "Number of tokens (1330) exceeded maximum context length (512).\n",
      "Number of tokens (1331) exceeded maximum context length (512).\n",
      "Number of tokens (1332) exceeded maximum context length (512).\n",
      "Number of tokens (1333) exceeded maximum context length (512).\n",
      "Number of tokens (1334) exceeded maximum context length (512).\n",
      "Number of tokens (1335) exceeded maximum context length (512).\n",
      "Number of tokens (1336) exceeded maximum context length (512).\n",
      "Number of tokens (1337) exceeded maximum context length (512).\n",
      "Number of tokens (1338) exceeded maximum context length (512).\n",
      "Number of tokens (1339) exceeded maximum context length (512).\n",
      "Number of tokens (1340) exceeded maximum context length (512).\n",
      "Number of tokens (1341) exceeded maximum context length (512).\n",
      "Number of tokens (1342) exceeded maximum context length (512).\n",
      "Number of tokens (1343) exceeded maximum context length (512).\n",
      "Number of tokens (1344) exceeded maximum context length (512).\n",
      "Number of tokens (1345) exceeded maximum context length (512).\n",
      "Number of tokens (1346) exceeded maximum context length (512).\n",
      "Number of tokens (1347) exceeded maximum context length (512).\n",
      "Number of tokens (1348) exceeded maximum context length (512).\n",
      "Number of tokens (1349) exceeded maximum context length (512).\n",
      "Number of tokens (1350) exceeded maximum context length (512).\n",
      "Number of tokens (1351) exceeded maximum context length (512).\n",
      "Number of tokens (1352) exceeded maximum context length (512).\n",
      "Number of tokens (1353) exceeded maximum context length (512).\n",
      "Number of tokens (1354) exceeded maximum context length (512).\n",
      "Number of tokens (1355) exceeded maximum context length (512).\n",
      "Number of tokens (1356) exceeded maximum context length (512).\n",
      "Number of tokens (1357) exceeded maximum context length (512).\n",
      "Number of tokens (1358) exceeded maximum context length (512).\n",
      "Number of tokens (1359) exceeded maximum context length (512).\n",
      "Number of tokens (1360) exceeded maximum context length (512).\n",
      "Number of tokens (1361) exceeded maximum context length (512).\n",
      "Number of tokens (1362) exceeded maximum context length (512).\n",
      "Number of tokens (1363) exceeded maximum context length (512).\n",
      "Number of tokens (1364) exceeded maximum context length (512).\n",
      "Number of tokens (1365) exceeded maximum context length (512).\n",
      "Number of tokens (1366) exceeded maximum context length (512).\n",
      "Number of tokens (1367) exceeded maximum context length (512).\n",
      "Number of tokens (1368) exceeded maximum context length (512).\n",
      "Number of tokens (1369) exceeded maximum context length (512).\n",
      "Number of tokens (1370) exceeded maximum context length (512).\n",
      "Number of tokens (1371) exceeded maximum context length (512).\n",
      "Number of tokens (1372) exceeded maximum context length (512).\n",
      "Number of tokens (1373) exceeded maximum context length (512).\n",
      "Number of tokens (1374) exceeded maximum context length (512).\n",
      "Number of tokens (1375) exceeded maximum context length (512).\n",
      "Number of tokens (1376) exceeded maximum context length (512).\n",
      "Number of tokens (1377) exceeded maximum context length (512).\n",
      "Number of tokens (1378) exceeded maximum context length (512).\n",
      "Number of tokens (1379) exceeded maximum context length (512).\n",
      "Number of tokens (1380) exceeded maximum context length (512).\n",
      "Number of tokens (1381) exceeded maximum context length (512).\n",
      "Number of tokens (1382) exceeded maximum context length (512).\n",
      "Number of tokens (1383) exceeded maximum context length (512).\n",
      "Number of tokens (1384) exceeded maximum context length (512).\n",
      "Number of tokens (1385) exceeded maximum context length (512).\n",
      "Number of tokens (1386) exceeded maximum context length (512).\n",
      "Number of tokens (1387) exceeded maximum context length (512).\n",
      "Number of tokens (1388) exceeded maximum context length (512).\n",
      "Number of tokens (1389) exceeded maximum context length (512).\n",
      "Number of tokens (1390) exceeded maximum context length (512).\n",
      "Number of tokens (1391) exceeded maximum context length (512).\n",
      "Number of tokens (1392) exceeded maximum context length (512).\n",
      "Number of tokens (1393) exceeded maximum context length (512).\n",
      "Number of tokens (1394) exceeded maximum context length (512).\n",
      "Number of tokens (1395) exceeded maximum context length (512).\n",
      "Number of tokens (1396) exceeded maximum context length (512).\n",
      "Number of tokens (1397) exceeded maximum context length (512).\n",
      "Number of tokens (1398) exceeded maximum context length (512).\n",
      "Number of tokens (1399) exceeded maximum context length (512).\n",
      "Number of tokens (1400) exceeded maximum context length (512).\n",
      "Number of tokens (1401) exceeded maximum context length (512).\n",
      "Number of tokens (1402) exceeded maximum context length (512).\n",
      "Number of tokens (1403) exceeded maximum context length (512).\n",
      "Number of tokens (1404) exceeded maximum context length (512).\n",
      "Number of tokens (1405) exceeded maximum context length (512).\n",
      "Number of tokens (1406) exceeded maximum context length (512).\n",
      "Number of tokens (1407) exceeded maximum context length (512).\n",
      "Number of tokens (1408) exceeded maximum context length (512).\n",
      "Number of tokens (1409) exceeded maximum context length (512).\n",
      "Number of tokens (1410) exceeded maximum context length (512).\n",
      "Number of tokens (1411) exceeded maximum context length (512).\n",
      "Number of tokens (1412) exceeded maximum context length (512).\n",
      "Number of tokens (1413) exceeded maximum context length (512).\n",
      "Number of tokens (1414) exceeded maximum context length (512).\n",
      "Number of tokens (1415) exceeded maximum context length (512).\n",
      "Number of tokens (1416) exceeded maximum context length (512).\n",
      "Number of tokens (1417) exceeded maximum context length (512).\n",
      "Number of tokens (1418) exceeded maximum context length (512).\n",
      "Number of tokens (1419) exceeded maximum context length (512).\n",
      "Number of tokens (1420) exceeded maximum context length (512).\n",
      "Number of tokens (1421) exceeded maximum context length (512).\n",
      "Number of tokens (1422) exceeded maximum context length (512).\n",
      "Number of tokens (1423) exceeded maximum context length (512).\n",
      "Number of tokens (1424) exceeded maximum context length (512).\n",
      "Number of tokens (1425) exceeded maximum context length (512).\n",
      "Number of tokens (1426) exceeded maximum context length (512).\n",
      "Number of tokens (1427) exceeded maximum context length (512).\n",
      "Number of tokens (1428) exceeded maximum context length (512).\n",
      "Number of tokens (1429) exceeded maximum context length (512).\n",
      "Number of tokens (1430) exceeded maximum context length (512).\n",
      "Number of tokens (1431) exceeded maximum context length (512).\n",
      "Number of tokens (1432) exceeded maximum context length (512).\n",
      "Number of tokens (1433) exceeded maximum context length (512).\n",
      "Number of tokens (1434) exceeded maximum context length (512).\n",
      "Number of tokens (1435) exceeded maximum context length (512).\n",
      "Number of tokens (1436) exceeded maximum context length (512).\n",
      "Number of tokens (1437) exceeded maximum context length (512).\n",
      "Number of tokens (1438) exceeded maximum context length (512).\n",
      "Number of tokens (1439) exceeded maximum context length (512).\n",
      "Number of tokens (1440) exceeded maximum context length (512).\n",
      "Number of tokens (1441) exceeded maximum context length (512).\n",
      "Number of tokens (1442) exceeded maximum context length (512).\n",
      "Number of tokens (1443) exceeded maximum context length (512).\n",
      "Number of tokens (1444) exceeded maximum context length (512).\n",
      "Number of tokens (1445) exceeded maximum context length (512).\n",
      "Number of tokens (1446) exceeded maximum context length (512).\n",
      "Number of tokens (1447) exceeded maximum context length (512).\n",
      "Number of tokens (1448) exceeded maximum context length (512).\n",
      "Number of tokens (1449) exceeded maximum context length (512).\n",
      "Number of tokens (1450) exceeded maximum context length (512).\n",
      "Number of tokens (1451) exceeded maximum context length (512).\n",
      "Number of tokens (1452) exceeded maximum context length (512).\n",
      "Number of tokens (1453) exceeded maximum context length (512).\n",
      "Number of tokens (1454) exceeded maximum context length (512).\n",
      "Number of tokens (1455) exceeded maximum context length (512).\n",
      "Number of tokens (1456) exceeded maximum context length (512).\n",
      "Number of tokens (1457) exceeded maximum context length (512).\n",
      "Number of tokens (1458) exceeded maximum context length (512).\n",
      "Number of tokens (1459) exceeded maximum context length (512).\n",
      "Number of tokens (1460) exceeded maximum context length (512).\n",
      "Number of tokens (1461) exceeded maximum context length (512).\n",
      "Number of tokens (1462) exceeded maximum context length (512).\n",
      "Number of tokens (1463) exceeded maximum context length (512).\n",
      "Number of tokens (1464) exceeded maximum context length (512).\n",
      "Number of tokens (1465) exceeded maximum context length (512).\n",
      "Number of tokens (1466) exceeded maximum context length (512).\n",
      "Number of tokens (1467) exceeded maximum context length (512).\n",
      "Number of tokens (1468) exceeded maximum context length (512).\n",
      "Number of tokens (1469) exceeded maximum context length (512).\n",
      "Number of tokens (1470) exceeded maximum context length (512).\n",
      "Number of tokens (1471) exceeded maximum context length (512).\n",
      "Number of tokens (1472) exceeded maximum context length (512).\n",
      "Number of tokens (1473) exceeded maximum context length (512).\n",
      "Number of tokens (1474) exceeded maximum context length (512).\n",
      "Number of tokens (1475) exceeded maximum context length (512).\n",
      "Number of tokens (1476) exceeded maximum context length (512).\n",
      "Number of tokens (1477) exceeded maximum context length (512).\n",
      "Number of tokens (1478) exceeded maximum context length (512).\n",
      "Number of tokens (1479) exceeded maximum context length (512).\n",
      "Number of tokens (1480) exceeded maximum context length (512).\n",
      "Number of tokens (1481) exceeded maximum context length (512).\n",
      "Number of tokens (1482) exceeded maximum context length (512).\n",
      "Number of tokens (1483) exceeded maximum context length (512).\n",
      "Number of tokens (1484) exceeded maximum context length (512).\n",
      "Number of tokens (1485) exceeded maximum context length (512).\n",
      "Number of tokens (1486) exceeded maximum context length (512).\n",
      "Number of tokens (1487) exceeded maximum context length (512).\n",
      "Number of tokens (1488) exceeded maximum context length (512).\n",
      "Number of tokens (1489) exceeded maximum context length (512).\n",
      "Number of tokens (1490) exceeded maximum context length (512).\n",
      "Number of tokens (1491) exceeded maximum context length (512).\n",
      "Number of tokens (1492) exceeded maximum context length (512).\n",
      "Number of tokens (1493) exceeded maximum context length (512).\n",
      "Number of tokens (1494) exceeded maximum context length (512).\n",
      "Number of tokens (1495) exceeded maximum context length (512).\n",
      "Number of tokens (1496) exceeded maximum context length (512).\n",
      "Number of tokens (1497) exceeded maximum context length (512).\n",
      "Number of tokens (1498) exceeded maximum context length (512).\n",
      "Number of tokens (1499) exceeded maximum context length (512).\n",
      "Number of tokens (1500) exceeded maximum context length (512).\n",
      "Number of tokens (1501) exceeded maximum context length (512).\n",
      "Number of tokens (1502) exceeded maximum context length (512).\n",
      "Number of tokens (1503) exceeded maximum context length (512).\n",
      "Number of tokens (1504) exceeded maximum context length (512).\n",
      "Number of tokens (1505) exceeded maximum context length (512).\n",
      "Number of tokens (1506) exceeded maximum context length (512).\n",
      "Number of tokens (1507) exceeded maximum context length (512).\n",
      "Number of tokens (1508) exceeded maximum context length (512).\n",
      "Number of tokens (1509) exceeded maximum context length (512).\n",
      "Number of tokens (1510) exceeded maximum context length (512).\n",
      "Number of tokens (1511) exceeded maximum context length (512).\n",
      "Number of tokens (1512) exceeded maximum context length (512).\n",
      "Number of tokens (1513) exceeded maximum context length (512).\n",
      "Number of tokens (1514) exceeded maximum context length (512).\n",
      "Number of tokens (1515) exceeded maximum context length (512).\n",
      "Number of tokens (1516) exceeded maximum context length (512).\n",
      "Number of tokens (1517) exceeded maximum context length (512).\n",
      "Number of tokens (1518) exceeded maximum context length (512).\n",
      "Number of tokens (1519) exceeded maximum context length (512).\n",
      "Number of tokens (1520) exceeded maximum context length (512).\n",
      "Number of tokens (1521) exceeded maximum context length (512).\n",
      "Number of tokens (1522) exceeded maximum context length (512).\n",
      "Number of tokens (1523) exceeded maximum context length (512).\n",
      "Number of tokens (1524) exceeded maximum context length (512).\n",
      "Number of tokens (1525) exceeded maximum context length (512).\n",
      "Number of tokens (1526) exceeded maximum context length (512).\n",
      "Number of tokens (1527) exceeded maximum context length (512).\n",
      "Number of tokens (1528) exceeded maximum context length (512).\n",
      "Number of tokens (1529) exceeded maximum context length (512).\n",
      "Number of tokens (1530) exceeded maximum context length (512).\n",
      "Number of tokens (1531) exceeded maximum context length (512).\n",
      "Number of tokens (1532) exceeded maximum context length (512).\n",
      "Number of tokens (1533) exceeded maximum context length (512).\n",
      "Number of tokens (1534) exceeded maximum context length (512).\n",
      "Number of tokens (1535) exceeded maximum context length (512).\n",
      "Number of tokens (1536) exceeded maximum context length (512).\n",
      "Number of tokens (1537) exceeded maximum context length (512).\n",
      "Number of tokens (1538) exceeded maximum context length (512).\n",
      "Number of tokens (1539) exceeded maximum context length (512).\n",
      "Number of tokens (1540) exceeded maximum context length (512).\n",
      "Number of tokens (1541) exceeded maximum context length (512).\n",
      "Number of tokens (1542) exceeded maximum context length (512).\n",
      "Number of tokens (1543) exceeded maximum context length (512).\n",
      "Number of tokens (1544) exceeded maximum context length (512).\n",
      "Number of tokens (1545) exceeded maximum context length (512).\n",
      "Number of tokens (1546) exceeded maximum context length (512).\n",
      "Number of tokens (1547) exceeded maximum context length (512).\n",
      "Number of tokens (1548) exceeded maximum context length (512).\n",
      "Number of tokens (1549) exceeded maximum context length (512).\n",
      "Number of tokens (1550) exceeded maximum context length (512).\n",
      "Number of tokens (1551) exceeded maximum context length (512).\n",
      "Number of tokens (1552) exceeded maximum context length (512).\n",
      "Number of tokens (1553) exceeded maximum context length (512).\n",
      "Number of tokens (1554) exceeded maximum context length (512).\n",
      "Number of tokens (1555) exceeded maximum context length (512).\n",
      "Number of tokens (1556) exceeded maximum context length (512).\n",
      "Number of tokens (1557) exceeded maximum context length (512).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output_text': 'The answer is not available in the information retrieval is not available in the answer is not available in the provided context is not available in the details are not available in the answer is not available in the answer is not available in the details about the detailed. Omkarthick\\n Omkarth\\nOmkarthickbox ____________  There is not available in the details on basis, No,   Please refer to provide all of course\\n    Available\\nNot available in the name is not available in the provided context does not available\\nThere are not available in the answer is not available in the information retrieval\\nThe answer is not available in the answer is not available in the answer is not available in the details are not available in the data scientist none of Omkarthesection:\\n Omkarthick box link forOmkarthese,  The answer is not available in the name is not available in the answer is not available in the provided context does not available in the answer is not available in the name is not available in the details are not available in the details about the details of course available in the answer is not available\\nThe answer is not available\\nAs per the details on\\nNot available\\n The data scientistAvailable in the email is not'}\n"
     ]
    }
   ],
   "source": [
    "response = chain(\n",
    "    {\"input_documents\":docs, \"question\": user_question}\n",
    "    , return_only_outputs=True)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
